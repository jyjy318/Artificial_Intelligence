{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Test_BoneClassification_JiYe_1770027.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bp5-Fo2T_alH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91b3992c-5388-4ddf-a9aa-e00379aaa387"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAj5Gq-AmBDL"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms, models"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ei87CgD3_1aR"
      },
      "source": [
        "from torch.autograd import Variable\n",
        "import torch.utils.data as data\n",
        "import pandas as pd\n",
        "import os\n",
        "from PIL import Image\n",
        "from torch.utils.data import DataLoader, TensorDataset\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTImOCj-Zeop"
      },
      "source": [
        "# Path for (unlabeled) test data\n",
        "test_path = '/content/drive/My Drive/PatternProject/Test/'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04e4sQjMZTpz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f167a5f-c573-47b6-fc6d-c7694593e18d"
      },
      "source": [
        "# Prepare test data set\n",
        "\n",
        "data =[]\n",
        "label =[]\n",
        "resize = transforms.Compose([transforms.CenterCrop(400)]) #crop to 400\n",
        "\n",
        "files = os.listdir(test_path)\n",
        "files.sort(); # so that resutls can be printed in the order of 'test01', 'test02', ... 'test80'\n",
        "\n",
        "print(files)\n",
        "\n",
        "for f in files:\n",
        "  img = Image.open(test_path+'/'+f,'r')\n",
        "  img = resize(img)\n",
        "  r,g,b = img.split()\n",
        "  one_img = np.asarray(np.float32(r)/255.0)\n",
        "  img = np.asarray([one_img])\n",
        "  data.append(img)\n",
        "  label.append(1) # dummy numbers (not to be used anyway)\n",
        "\n",
        "data = np.array(data, dtype='float32')\n",
        "label = np.array(label, dtype='int64')\n",
        "\n",
        "test_X = torch.from_numpy(data)\n",
        "test_Y = torch.from_numpy(label)\n",
        "test_X = test_X.type(torch.cuda.FloatTensor)\n",
        "test_Y = test_Y.type(torch.cuda.LongTensor)\n",
        "test_dataset = TensorDataset(test_X, test_Y)\n",
        "#test_dataset = TensorDataset(test_X)\n",
        "test_loader = DataLoader(test_dataset, batch_size = 80, shuffle=False) # set batch size to 80 to print all the predictions in one vector\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['test01.jpg', 'test02.jpg', 'test03.jpg', 'test04.jpg', 'test05.jpg', 'test06.jpg', 'test07.jpg', 'test08.jpg', 'test09.jpg', 'test10.jpg', 'test11.jpg', 'test12.jpg', 'test13.jpg', 'test14.jpg', 'test15.jpg', 'test16.jpg', 'test17.jpg', 'test18.jpg', 'test19.jpg', 'test20.jpg', 'test21.jpg', 'test22.jpg', 'test23.jpg', 'test24.jpg', 'test25.jpg', 'test26.jpg', 'test27.jpg', 'test28.jpg', 'test29.jpg', 'test30.jpg', 'test31.jpg', 'test32.jpg', 'test33.jpg', 'test34.jpg', 'test35.jpg', 'test36.jpg', 'test37.jpg', 'test38.jpg', 'test39.jpg', 'test40.jpg', 'test41.jpg', 'test42.jpg', 'test43.jpg', 'test44.jpg', 'test45.jpg', 'test46.jpg', 'test47.jpg', 'test48.jpg', 'test49.jpg', 'test50.jpg', 'test51.jpg', 'test52.jpg', 'test53.jpg', 'test54.jpg', 'test55.jpg', 'test56.jpg', 'test57.jpg', 'test58.jpg', 'test59.jpg', 'test60.jpg', 'test61.jpg', 'test62.jpg', 'test63.jpg', 'test64.jpg', 'test65.jpg', 'test66.jpg', 'test67.jpg', 'test68.jpg', 'test69.jpg', 'test70.jpg', 'test71.jpg', 'test72.jpg', 'test73.jpg', 'test74.jpg', 'test75.jpg', 'test76.jpg', 'test77.jpg', 'test78.jpg', 'test79.jpg', 'test80.jpg', 'test81.jpg', 'test82.jpg', 'test83.jpg', 'test84.jpg', 'test85.jpg', 'test86.jpg', 'test87.jpg', 'test88.jpg', 'test89.jpg', 'test90.jpg']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2En2mL7ABQ4"
      },
      "source": [
        "# Build convolutional neural net\n",
        "# IMPORTNT: This structure should be same as the one used for training (so simply copy and paste the correponding codes)\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "           \n",
        "            nn.Conv2d(1, 16, 3), \n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16,16, 3), \n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2,2),  \n",
        "\n",
        "            nn.Conv2d(16, 32, 3),  \n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 32, 3), \n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2,2),   \n",
        "\n",
        "            nn.Conv2d(32, 64, 3), \n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, 3), \n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, 3), \n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2,2),  \n",
        "\n",
        "        )\n",
        "        \n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(45*45*64,64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.3),\n",
        "            nn.Linear(64,32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32,2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = x.view(x.size()[0],-1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "model = Net()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnxXbcwm_kkp"
      },
      "source": [
        "model = torch.load('/content/drive/My Drive/PatternProject/Model_JiYe_1770027')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgHWyvljhBIC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c1e44e5-c7e2-4ef0-af4e-69aad65fb177"
      },
      "source": [
        "model.eval()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "a = []\n",
        "\n",
        "#각각 80,10길이의 result로 두개가 나와서 하나의 리스트로 합치는 과정 포함\n",
        "for inputs, labels in test_loader:\n",
        "    inputs, labels = Variable(inputs), Variable(labels)\n",
        "    output = model(inputs)\n",
        "    idx, pred = output.max(1)\n",
        "    pred = (pred.detach().cpu().numpy())\n",
        "    print('Test results : {}'.format(pred))\n",
        "    b = pred.tolist()\n",
        "    a.append(b)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test results : [0 0 1 0 0 1 0 1 1 0 0 1 1 0 1 1 1 0 1 1 1 1 0 0 1 0 0 0 1 1 0 1 0 0 0 0 1\n",
            " 0 1 1 0 0 0 1 1 1 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 1 1 0 1 0 0 1 0 1 1 0 0\n",
            " 0 0 0 1 0 0]\n",
            "Test results : [0 0 1 1 0 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poM9TYc8q79S",
        "outputId": "5f839f1a-2e9f-4364-c2d0-d273b4abdf1d"
      },
      "source": [
        "#2차원 리스트로 되어있어서 하나의 리스트로 변환\n",
        "final_result = []\n",
        "for i in range(80):\n",
        "  final_result.append(a[0][i])\n",
        "\n",
        "for j in range(10):\n",
        "  final_result.append(a[1][j])\n",
        "\n",
        "print(type(final_result), len(final_result))\n",
        "print(final_result)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'> 90\n",
            "[0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejLj3AF8uJPU"
      },
      "source": [
        "import csv \n",
        "import pandas as pd\n",
        "data = np.array(files)\n",
        "data.T\n",
        "z1 =  data.tolist()\n",
        "\n",
        "data2 =  np.array(final_result)\n",
        "data2.T\n",
        "z2 = data2.tolist()\n",
        "    \n",
        "z3 = pd.DataFrame(z1)\n",
        "z4 = pd.DataFrame(z2)\n",
        "z5= pd.concat([z3,z4],axis=1)\n",
        "z5\n",
        "z5.to_csv(\"/content/drive/My Drive/PatternProject/Result_JiYe_1770027.csv\", mode='w',header=False,index = None)"
      ],
      "execution_count": 11,
      "outputs": []
    }
  ]
}