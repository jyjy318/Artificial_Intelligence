{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"code.ipynb","provenance":[],"authorship_tag":"ABX9TyPrMJ3TjaFoe2KEkUrKds4L"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"wNRvr9CRM4GI"},"source":["#!/usr/bin/python\r\n","\r\n","import csv\r\n","import os\r\n","import numpy as np\r\n","from torch.utils import data\r\n","from torchvision import datasets, transforms\r\n","import random\r\n","from multiprocessing import cpu_count\r\n","import torch\r\n","from PIL import Image, ImageDraw #masking\r\n","from sklearn.model_selection import train_test_split\r\n","\r\n","def transform_image(image):\r\n","    custom_transformer = transforms.Compose([\r\n","                transforms.ToTensor(),\r\n","                transforms.Resize((270, 270))])\r\n","    image_tr = custom_transformer(image)\r\n","\r\n","    return image_tr\r\n","\r\n","def convert_label(label) :\r\n","    if label == 'Wake' : label = 0\r\n","    elif label == 'N1' : label = 1\r\n","    elif label == 'N2' : label = 2\r\n","    elif label == 'N3' : label = 3\r\n","    elif label == 'REM' : label = 4\r\n","\r\n","    return label\r\n","\r\n","\r\n","class CustomDataset(data.Dataset):\r\n","    def __init__(self, phase='train', root=''):\r\n","        self.root = root\r\n","        self.phase = phase\r\n","        self.data = {}\r\n","\r\n","        if self.phase == \"train\" or self.phase == 'validation':\r\n","            path = os.path.join(root,'train'+'set-for_user.csv')\r\n","        else:\r\n","            path = os.path.join(root,self.phase+'set-for_user.csv')\r\n","\r\n","        f = open(path, 'r', encoding='utf-8-sig')\r\n","        rdr = csv.reader(f)\r\n","\r\n","        lst_img = []\r\n","        lst_label = []\r\n","\r\n","        #if self.phase == 'train':\r\n","        #    rdr = rdr[:448000]\r\n","        #elif self.phasee == 'validation':\r\n","        #    rdr = rdr[448000:]\r\n","        #else: rdr = rdr\r\n","\r\n","        for idx, item in enumerate(rdr):\r\n","            path_img = os.path.join(self.root, item[0], item[1])\r\n","            if self.phase == 'train' or self.phase == 'validation' :\r\n","                label = item[2]\r\n","                label = convert_label(label)\r\n","            else : label = -1\r\n","\r\n","            lst_img.append(path_img)\r\n","            lst_label.append(label)\r\n","\r\n","        if self.phase == 'train':\r\n","            lst_img = lst_img[:448460]\r\n","            lst_label = lst_label[:448460]\r\n","\r\n","        elif self.phase == 'validation':\r\n","            lst_img = lst_img[448460:]\r\n","            lst_label = lst_label[448460:]\r\n","        else:\r\n","            lst_img = lst_img\r\n","            lst_label = lst_label\r\n","\r\n","        self.data['image'] = lst_img\r\n","        self.data['label'] = lst_label\r\n","\r\n","\r\n","    def __getitem__(self, index):\r\n","        path = self.data['image'][index]\r\n","        img = Image.open(path)\r\n","\r\n","        # masking\r\n","        #im = ImageDraw.Draw(img)\r\n","        #im.rectangle(((0,107),(480,204)), fill = (0,0,0),outline=(0, 0,0), width=2)\r\n","        #im.rectangle(((0,225),(480,270)), fill = (0,0,0),outline=(0, 0,0), width=2)\r\n","\r\n","        img = transform_image(img)\r\n","        label = self.data['label'][index]\r\n","        return img, label\r\n","\r\n","    def __len__(self):\r\n","        return len(self.data['image'])\r\n","\r\n","\r\n","def data_loader(phase, path_dataset = '../../../DATA', batch_size = 32, num_workers = 1):\r\n","\r\n","\r\n","    if phase == 'train'  or phase =='validation':\r\n","        train_dataset = CustomDataset(phase='train', root=path_dataset)\r\n","        valid_dataset = CustomDataset(phase='validation', root=path_dataset)\r\n","\r\n","        print(len(train_dataset))\r\n","        print(len(valid_dataset))\r\n","\r\n","        #train_dataset, test_dataset = train_test_split(dataset, test_size = 0.2, shuffle= False)\r\n","        #print(len(train_dataset))\r\n","        #train_size = int(0.8 * len(dataset))\r\n","        #test_size = len(dataset) - train_size\r\n","        #train_dataset, test_dataset = data.random_split(dataset, [train_size, test_size])\r\n","\r\n","        if phase == 'train':\r\n","            dataloader = data.DataLoader(dataset=train_dataset, batch_size=batch_size, num_workers = num_workers, shuffle=True)\r\n","        else:\r\n","            dataloader = data.DataLoader(dataset=valid_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True)\r\n","    else :\r\n","        dataset = CustomDataset(phase=phase, root=path_dataset)\r\n","        dataloader = data.DataLoader(dataset=dataset, batch_size=batch_size, num_workers = num_workers, shuffle=False)\r\n","\r\n","    return dataloader\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"04b4_ILiM5gI"},"source":["\r\n","#!/usr/bin/python\r\n","\r\n","from J_loader3 import data_loader\r\n","import csv\r\n","import torch\r\n","import os\r\n","\r\n","import numpy as np\r\n","import torch.nn as nn\r\n","import torch.nn.functional as F\r\n","\r\n","#from pytorch_lightning.metrics import F1\r\n","\r\n","def save_model(model, optimizer) :\r\n","    model_cpu = model.to('cpu')\r\n","    state = {\r\n","        'model' : model_cpu.state_dict(),\r\n","        'optimizer' : optimizer.state_dict()}\r\n","       # 'scheduler' : scheduler.state_dict()\r\n","    if not(os.path.isdir('./saved_model')) : os.mkdir('./saved_model')\r\n","    torch.save(state, './saved_model/saved_model_270.pth')\r\n","\r\n","class CNN(nn.Module):\r\n","\r\n","    def __init__ (self):\r\n","        super(CNN, self).__init__()\r\n","        self.conv1 = nn.Conv2d(\r\n","        in_channels = 1, out_channels = 8,\r\n","        kernel_size = 7,\r\n","        padding = 0)\r\n","        self.conv2 = nn.Conv2d(\r\n","        in_channels = 8, out_channels = 16,\r\n","        kernel_size = 7,\r\n","        padding = 1)\r\n","        self.conv3 = nn.Conv2d(\r\n","        in_channels = 16, out_channels = 16,\r\n","        kernel_size = 7,\r\n","        padding = 1)\r\n","        self.conv4 = nn.Conv2d(\r\n","        in_channels = 16, out_channels = 16,\r\n","        kernel_size = 5,\r\n","        padding = 1)\r\n","        self.conv5 = nn.Conv2d(\r\n","        in_channels = 16, out_channels = 32,\r\n","        kernel_size = 5,\r\n","        padding = 1)\r\n","\r\n","        self.pool = nn.MaxPool2d(\r\n","        kernel_size = 2,\r\n","        stride = 2)\r\n","        self.Drop = nn.Dropout(p=0.2)\r\n","\r\n","        self.fc1 = nn.Linear(6 * 6 * 32, 512)\r\n","        self.fc2 = nn.Linear(512, 5)\r\n","\r\n","    def forward(self, x):\r\n","        x = self.conv1(x)\r\n","        x = F.relu(x)\r\n","        x = self.pool(x)\r\n","        x = self.Drop(x)\r\n","        x = self.conv2(x)\r\n","        x = F.relu(x)\r\n","        x = self.pool(x)\r\n","        x = self.Drop(x)\r\n","        x = self.conv3(x)\r\n","        x = F.relu(x)\r\n","        x = self.pool(x)\r\n","        x = self.Drop(x)\r\n","        x = self.conv4(x)\r\n","        x = F.relu(x)\r\n","        x = self.pool(x)\r\n","        x = self.Drop(x)\r\n","        x = self.conv5(x)\r\n","        x = F.relu(x)\r\n","        x = self.pool(x)\r\n","        x = self.Drop(x)\r\n","\r\n","        x = x.view(-1, 6 * 6 * 32)\r\n","        x = self.fc1(x)\r\n","        x = F.relu(x)\r\n","        x = self.fc2(x)\r\n","        x = F.log_softmax(x)\r\n","\r\n","        return x\r\n","\r\n","def train_val():\r\n","\r\n","    # define or import model\r\n","    model = CNN().to(DEVICE)\r\n","    # define loss fc\r\n","    loss_fn = nn.CrossEntropyLoss()\r\n","    # define optimizer\r\n","    optimizer = torch.optim.Adam(\r\n","        model.parameters(),\r\n","        lr = 0.001)\r\n","    # define scheduler\r\n","    #scheduler = StepLR(optimizer, step_size = 5, gamma =0.5)\r\n","    print(model)\r\n","\r\n","    train_loader = data_loader(phase='train', batch_size=32)\r\n","    valid_loader = data_loader(phase='validation', batch_size=32)\r\n","\r\n","    for (X_train, y_train) in train_loader:\r\n","        print(X_train.size(), X_train.type())\r\n","        print(y_train.size(), y_train.type())\r\n","        break\r\n","\r\n","    epoch = 10\r\n","    for Epoch in range(0, epoch) :\r\n","        lst_out = []\r\n","        lst_label = []\r\n","\r\n","        model.train()\r\n","        train_loss = 0\r\n","        correct = 0\r\n","        for batch_idx, (image, label) in enumerate(train_loader):\r\n","            image = image.to(DEVICE)\r\n","            label = label.to(DEVICE)\r\n","            optimizer.zero_grad()\r\n","            ### Example ###\r\n","            out = model(image)\r\n","            ### Calculate loss, backward loss and optimizer step ###\r\n","            loss = loss_fn(out, label)\r\n","            train_loss += loss.item()\r\n","            prediction = out.max(1, keepdim = True)[1]\r\n","            correct += prediction.eq(label.view_as(prediction)).sum().item()\r\n","            #optimizer.zero_grad()\r\n","            loss.backward()\r\n","            optimizer.step()\r\n","\r\n","            if batch_idx % 1000 == 0:\r\n","                print(\"Train Epoch: {} [{}/{}({:.0f}%)]\".format(Epoch+1, batch_idx*len(image), len(train_loader.dataset), 100.*batch_idx/len(train_loader)))\r\n","\r\n","        train_loss /= len(train_loader.dataset)\r\n","        train_accuracy = 100.*correct/len(train_loader.dataset)\r\n","\r\n","\r\n","        model.eval()\r\n","        valid_loss = 0\r\n","        correct = 0\r\n","        with torch.no_grad():\r\n","            for image, label in valid_loader:\r\n","                image = image.to(DEVICE)\r\n","                label = label.to(DEVICE)\r\n","                output = model(image)\r\n","                valid_loss += loss_fn(output, label).item()\r\n","                prediction = output.max(1, keepdim = True)[1]\r\n","                lst_out += prediction\r\n","                lst_label +=label\r\n","                correct += prediction.eq(label.view_as(prediction)).sum().item()\r\n","\r\n","        valid_loss /= len(valid_loader.dataset)\r\n","        valid_accuracy = 100.*correct/len(valid_loader.dataset)\r\n","\r\n","\r\n","            ### Sample ###\r\n","           # lst_out += [0,1,2,3,4]\r\n","           # lst_label += [0,1,2,3,4]\r\n","            ###########\r\n","\r\n","        print(\"\\n [EPOCH: {}] \\n Train Loss: {:.4f}, \\t Train Accuracy: {:.2f}\".format(Epoch+1, train_loss, train_accuracy))\r\n","        print(\" Valid Loss: {:.4f}, \\t Valid Accuracy: {:.2f}\".format(valid_loss, valid_accuracy))\r\n","        #scheduler.step()\r\n","    save_model(model, optimizer)\r\n","\r\n","    #f1 = F1(num_classes=5, average = 'macro')\r\n","    #print(lst_out, lst_label)\r\n","    #print(f1(torch.tensor(lst_out), torch.tensor(lst_label)))\r\n","\r\n","    #print(\"\\n [EPOCH: {}] \\n Train Loss: {:.4f}, \\t Train Accuracy: {:.2f}\".format(Epoch+1, train_loss, train_accuracy))\r\n","    #print(\" Valid Loss: {:.4f}, \\t Valid Accuracy: {:.2f}\".format(valid_loss, valid_accuracy))\r\n","\r\n","def test() :\r\n","    dic_label = {0:'Wake', 4:'REM', 1:'N1', 2:'N2', 3:'N3'}\r\n","    test_loader = data_loader(phase='test', batch_size= 32)\r\n","    f1 = open('./test_result_270.csv', 'w', encoding ='utf-8-sig', newline='')\r\n","    wr = csv.writer(f1)\r\n","    lst_out = []\r\n","    #lst_label = []\r\n","    ct = 0\r\n","\r\n","\r\n","    ### Example ###\r\n","\r\n","    #DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # use GPU (CPU는 None으로 설정)\r\n","    print(DEVICE)\r\n","    # define or import model\r\n","    model = CNN()\r\n","    # load model\r\n","    state = torch.load('./saved_model/saved_model_270.pth')\r\n","    model.load_state_dict(state['model'])\r\n","    #DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # use GPU (CPU는 None으로 설정)\r\n","    #print(DEVICE)\r\n","    model = model.to(DEVICE)\r\n","\r\n","    for batch_idx, (image, _) in enumerate(test_loader):\r\n","        image = image.to(DEVICE)\r\n","        output = model(image)\r\n","        prediction = output.max(1, keepdim = True)[1]\r\n","        #print(prediction)\r\n","        lst_out +=prediction\r\n","       # lst_label +=label\r\n","\r\n","        #example\r\n","        #lst_out = [0,1,2,3,4]\r\n","\r\n","        #print(lst_out)\r\n","        if batch_idx % 1000 == 0:\r\n","            print(\"[{}/{}({:.0f}%)]\".format(batch_idx*len(image), len(test_loader.dataset), 100.*batch_idx/len(test_loader)))\r\n","    for idx, item in enumerate(lst_out) :\r\n","        if idx % 1000 == 0:\r\n","            print(\"[{}/{}({:.0f}%)]\".format(idx*len(image), len(test_loader.dataset), 100.*idx/len(test_loader)))\r\n","\r\n","        wr.writerows([[dic_label[item[0].cpu().numpy().item()]]])\r\n","\r\n","if __name__ == \"__main__\":\r\n","\r\n","    DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # use GPU (CPU는 None으로 설정)\r\n","    print(DEVICE)\r\n","\r\n","    train_val()\r\n","    test()"],"execution_count":null,"outputs":[]}]}